# Homework 2 Corpus Analysis.

## Description
##### This Python script converts a dataset containing 200 documents of congressional hearings relating to Donald Trump after he lost the election, and after he won the election, to a bag of words format. Additionally, it uses Naive Bayes probabilities to calculate the log-likelihood of certain terms belonging to those previously mentioned categories. Topic modeling was then performed to allow users better visualization and interpretation.

## Requirements:
##### Required libraries include string, nltk, matplotlib, gensim, and pyLDAvis.
##### You can install the required libraries using pip:
##### pip install string nltk matplotlib gensim pyLDAvis

## How to Use
##### 1. Place the Python script in the desired directory.
##### 2. Have the documents belonging to one category and the other in their own directories inside a directory in which the python file is located. 
##### 3. Be mindful of the code based on where exactly where your files for everything are located (as well as the .txt, .html, and .csv files produced) 
##### 4. You likely will have to edit certain filters in the normalization, as well as the naming conventions for directories and files!!!
##### 5. Run the script from the command line with the following format:
##### python code.py

## Generative AI Use
##### Generative AI was used as outlined in the Report: homework2_report.pdf. It was also used partially in creating this README file.
